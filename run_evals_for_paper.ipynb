{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from PMM_for_images import ImageEncoder, ClassifierNet\n",
    "\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Categorical\n",
    "from copy import deepcopy\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pmm(image, net, ps, lbls,cut=5):\n",
    "        \"\"\"\n",
    "        image is some image dataset\n",
    "        \"\"\"\n",
    "        x_locs = net(image.unsqueeze(0))[0]\n",
    "\n",
    "        idks = torch.exp(-1*(torch.linalg.vector_norm(x_locs-ps,dim=1)))\n",
    "        top100_inds = torch.topk(idks, cut)[1]\n",
    "        p = F.softmax(idks[top100_inds])\n",
    "        \n",
    "        img_label = np.random.choice(lbls[top100_inds],p=p.detach().numpy() )\n",
    "\n",
    "\n",
    "        return img_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_precisions(inputs, target):\n",
    "    \"\"\"\n",
    "    @param inputs: dimension NxC where C is the number of imputation models and N is the number of observations\n",
    "    @param target: vector containing real labels of dimension Nx1 where N is the number of observations\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    accuracy_scores = [ 0 for i in range(inputs.shape[1])]\n",
    "    for (i,(guesses, true_val)) in enumerate(zip(inputs, target)):\n",
    "        for t in range(len(accuracy_scores)):\n",
    "            if i == 0:\n",
    "                accuracy_scores[t] = 1 if true_val == guesses[t] else 0\n",
    "            else:\n",
    "                incr = 1 if true_val == guesses[t] else 0\n",
    "                accuracy_scores[t] = accuracy_scores[t]*(i)/(i+1) + incr/(i+1)\n",
    "    return accuracy_scores"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating all three as missingness increase (MNAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1000 = pickle.load(open(\"pmm_data_alpha_1000.pkl\",'rb'))\n",
    "data_5000 = pickle.load(open(\"pmm_data_alpha_5000.pkl\",'rb'))\n",
    "data_10000 = pickle.load(open(\"pmm_data_alpha_10000.pkl\",'rb'))\n",
    "data_14000 = pickle.load(open(\"pmm_data_alpha_14000.pkl\",'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_labels_1000 = [i[1] for i in data_1000['missing']]\n",
    "real_labels_5000 = [i[1] for i in data_5000['missing']]\n",
    "real_labels_10000 = [i[1] for i in data_10000['missing']]\n",
    "real_labels_14000 = [i[1] for i in data_14000['missing']]\n",
    "obs_img_1000 = [i[0] for i in data_1000['obs']]\n",
    "obs_img_5000 = [i[0] for i in data_5000['obs']]\n",
    "obs_img_10000 = [i[0] for i in data_10000['obs']]\n",
    "obs_img_14000 = [i[0] for i in data_14000['obs']]\n",
    "obs_lbls_1000 = np.array([i[1] for i in data_1000['obs']])\n",
    "obs_lbls_5000 = np.array([i[1] for i in data_5000['obs']])\n",
    "obs_lbls_10000 = np.array([i[1] for i in data_10000['obs']])\n",
    "obs_lbls_14000 = np.array([i[1] for i in data_14000['obs']])\n",
    "\n",
    "missing_1000 = data_1000['missing']\n",
    "missing_5000 = data_5000['missing']\n",
    "missing_10000 = data_10000['missing']\n",
    "missing_14000 = data_14000['missing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nathandelara/mcgill/u2/math782/fin_proj3/PMM_for_images.py:86: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = F.softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/34929 [00:00<?, ?it/s]/var/folders/ct/kvp_zk9j387g9f0jks9lbxvc0000gn/T/ipykernel_87929/485499444.py:9: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  p = F.softmax(idks[top100_inds])\n",
      "100%|██████████| 34929/34929 [09:09<00:00, 63.57it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23895/23895 [07:05<00:00, 56.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5630/5630 [02:08<00:00, 43.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1146/1146 [00:25<00:00, 45.47it/s]\n"
     ]
    }
   ],
   "source": [
    "cc1 = torch.load(\"net_classifier_alpha_1000.pt\")\n",
    "cc5 = torch.load(\"net_classifier_alpha_5000.pt\")\n",
    "cc10 = torch.load(\"net_classifier_alpha_10000.pt\")\n",
    "cc14 = torch.load(\"net_classifier_alpha_14000.pt\")\n",
    "ca1 = torch.load(\"net_autoencoder_alpha_1000.pt\")\n",
    "ca5 = torch.load(\"net_autoencoder_alpha_5000.pt\")\n",
    "ca10 = torch.load(\"net_autoencoder_alpha_10000.pt\")\n",
    "ca14 = torch.load(\"net_autoencoder_alpha_14000.pt\")\n",
    "\n",
    "n_imputations = 5\n",
    "\n",
    "\n",
    "precs_1000 = []\n",
    "precs_5000 = []\n",
    "precs_10000 = []\n",
    "precs_14000 = []\n",
    "\n",
    "\n",
    "pc_1 = cc1(torch.stack(obs_img_1000))\n",
    "pc_5 = cc5(torch.stack(obs_img_5000))\n",
    "pc_10 = cc10(torch.stack(obs_img_10000))\n",
    "pc_14 = cc14(torch.stack(obs_img_14000))\n",
    "pa_1 = ca1(torch.stack(obs_img_1000))\n",
    "pa_5 = ca5(torch.stack(obs_img_5000))\n",
    "pa_10 = ca10(torch.stack(obs_img_10000))\n",
    "pa_14 = ca14(torch.stack(obs_img_14000))\n",
    "\n",
    "\n",
    "## classifier on all three\n",
    "labels_1 = [[],[],[], [],[]]\n",
    "print('11s')\n",
    "for img in tqdm(missing_1000):\n",
    "\n",
    "        image, pred_label_pc = img[0], img[1]\n",
    "        \n",
    "        for i in range(5):\n",
    "                pred_label_pa = pmm(image, ca1 ,pa_1, obs_lbls_1000)\n",
    "                pred_label_pc = pmm(image, cc1,pc_1, obs_lbls_1000)\n",
    "                classifier_probs = cc1(image.unsqueeze(0))\n",
    "                classifier_label = Categorical(classifier_probs).sample().item()\n",
    "\n",
    "\n",
    "                labels_1[i].append((pred_label_pa, pred_label_pc, classifier_label))\n",
    "\n",
    "\n",
    "\n",
    "labels_5 = [[],[],[], [],[]]\n",
    "print('51s')\n",
    "for img in tqdm(missing_5000):\n",
    "\n",
    "        image, pred_label_pc = img[0], img[1]\n",
    "        \n",
    "        for i in range(5):\n",
    "                pred_label_pa = pmm(image, ca5,pa_5, obs_lbls_5000)\n",
    "                pred_label_pc = pmm(image, cc5,pc_5, obs_lbls_5000)\n",
    "                classifier_probs = cc5(image.unsqueeze(0))\n",
    "                classifier_label = Categorical(classifier_probs).sample().item()\n",
    "\n",
    "\n",
    "                labels_5[i].append((pred_label_pa, pred_label_pc, classifier_label))\n",
    "\n",
    "\n",
    "labels_10 = [[],[],[], [],[]]\n",
    "print('10s')\n",
    "for img in tqdm(missing_10000):\n",
    "\n",
    "        image, pred_label_pc = img[0], img[1]\n",
    "        \n",
    "        for i in range(5):\n",
    "                pred_label_pa = pmm(image, ca10,pa_10, obs_lbls_10000)\n",
    "                pred_label_pc = pmm(image, cc10,pc_10, obs_lbls_10000)\n",
    "                classifier_probs = cc10(image.unsqueeze(0))\n",
    "                classifier_label = Categorical(classifier_probs).sample().item()\n",
    "\n",
    "\n",
    "                labels_10[i].append((pred_label_pa, pred_label_pc, classifier_label))\n",
    "\n",
    "\n",
    "labels_14 = [[],[],[], [],[]]\n",
    "print('14s')\n",
    "for img in tqdm(missing_14000):\n",
    "\n",
    "        image, pred_label_pc = img[0], img[1]\n",
    "        \n",
    "        for i in range(5):\n",
    "                pred_label_pa = pmm(image, ca14, pa_14, obs_lbls_14000)\n",
    "                pred_label_pc = pmm(image, cc14, pc_14, obs_lbls_14000)\n",
    "                classifier_probs = cc14(image.unsqueeze(0))\n",
    "                classifier_label = Categorical(classifier_probs).sample().item()\n",
    "\n",
    "\n",
    "                labels_14[i].append((pred_label_pa, pred_label_pc, classifier_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#precision for 11\n",
    "precs_1 = []\n",
    "for i in range(len(labels_1)):\n",
    "    precs_1.append(get_precisions(np.array(labels_1[i]), np.array(real_labels_1000)))\n",
    "\n",
    "precs_1 = np.array(precs_1)\n",
    "\n",
    "#precisins for 51\n",
    "precs_5 = []\n",
    "for i in range(len(labels_5)):\n",
    "    precs_5.append(get_precisions(np.array(labels_5[i]), np.array(real_labels_5000)))\n",
    "\n",
    "precs_5 = np.array(precs_5)\n",
    "\n",
    "#precisions for 101\n",
    "precs_10 = []\n",
    "for i in range(len(labels_10)):\n",
    "    precs_10.append(get_precisions(np.array(labels_10[i]), np.array(real_labels_10000)))\n",
    "\n",
    "precs_10 = np.array(precs_10)\n",
    "\n",
    "#precisions for 201\n",
    "precs_14 = []\n",
    "for i in range(len(labels_14)):\n",
    "    precs_14.append(get_precisions(np.array(labels_14[i]), np.array(real_labels_14000)))\n",
    "\n",
    "precs_14 = np.array(precs_14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.24918549, 0.11012626, 0.11149475]),\n",
       " array([2.41293576e-03, 1.09011894e-03, 1.40255360e-05]))"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precs_1.mean(axis=0), precs_1.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0001402"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.402e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.25021134, 0.10358652, 0.05900816]),\n",
       " array([0.00155496, 0.00113455, 0.        ]))"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precs_5.mean(axis=0), precs_5.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.23829485, 0.15179396, 0.18838366]),\n",
       " array([0.00424151, 0.00215089, 0.00300509]))"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precs_10.mean(axis=0), precs_10.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.26771379, 0.09546248, 0.09598604]),\n",
       " array([0.00735059, 0.00545218, 0.        ]))"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precs_14.mean(axis=0), precs_14.std(axis=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the different types of PMM (MAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = torch.load(\"net_classifier.pt\")\n",
    "ca = torch.load(\"net_autoencoder.pt\")\n",
    "\n",
    "\n",
    "data = pickle.load(open('pmm_data.pkl','rb'))\n",
    "real_labels = [i[1] for i in data['missing']]\n",
    "obs_img = [i[0] for i in data['obs']]\n",
    "obs_lbls = np.array([i[1] for i in data['obs']])\n",
    "missing = data['missing']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### type 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/11127 [00:00<?, ?it/s]/var/folders/ct/kvp_zk9j387g9f0jks9lbxvc0000gn/T/ipykernel_90727/485499444.py:9: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  p = F.softmax(idks[top100_inds])\n",
      "100%|██████████| 11127/11127 [03:26<00:00, 53.88it/s]\n"
     ]
    }
   ],
   "source": [
    "pc = cc(torch.stack(obs_img))\n",
    "pa = ca(torch.stack(obs_img))\n",
    "labels_type_0 = [[],[],[],[],[]]\n",
    "for img in tqdm(missing):\n",
    "\n",
    "        image, pred_label_pc = img[0], img[1]\n",
    "        \n",
    "        for i in range(5):\n",
    "                pred_label_pa = pmm(image, ca, pa, obs_lbls)\n",
    "                pred_label_pc = pmm(image, cc, pc, obs_lbls)\n",
    "                classifier_probs = cc(image.unsqueeze(0))\n",
    "                classifier_label = Categorical(classifier_probs).sample().item()\n",
    "\n",
    "\n",
    "                labels_type_0[i].append((pred_label_pa, pred_label_pc, classifier_label))\n",
    "precs_t0 = []\n",
    "for i in range(len(labels_type_0)):\n",
    "    precs_t0.append(get_precisions(np.array(labels_type_0[i]), np.array(real_labels)))\n",
    "\n",
    "precs_t0 = np.array(precs_t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.25144244, 0.10346005, 0.04502561]),\n",
       " array([0.00210798, 0.00186742, 0.        ]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precs_t0.mean(axis=0), precs_t0.std(axis=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### type 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/11127 [00:00<?, ?it/s]/var/folders/ct/kvp_zk9j387g9f0jks9lbxvc0000gn/T/ipykernel_87929/485499444.py:9: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  p = F.softmax(idks[top100_inds])\n",
      "100%|██████████| 11127/11127 [04:09<00:00, 44.54it/s]\n"
     ]
    }
   ],
   "source": [
    "#need to get dot b\n",
    "sd = 1e-2\n",
    "\n",
    "cadot = deepcopy(ca)\n",
    "ccdot = deepcopy(cc)\n",
    "for param in cadot.parameters():\n",
    "    param.data.copy_(param.data + np.random.random()*sd)\n",
    "for param in ccdot.parameters():\n",
    "    param.data.copy_(param.data + np.random.random()*sd)\n",
    "\n",
    "\n",
    "pc = cc(torch.stack(obs_img))\n",
    "pa = ca(torch.stack(obs_img))\n",
    "labels_type_1 = [[],[],[],[],[]]\n",
    "for img in tqdm(missing):\n",
    "\n",
    "        image, pred_label_pc = img[0], img[1]\n",
    "        \n",
    "        for i in range(5):\n",
    "                pred_label_pa = pmm(image, cadot, pa, obs_lbls)\n",
    "                pred_label_pc = pmm(image, ccdot, pc, obs_lbls)\n",
    "                classifier_probs = cc(image.unsqueeze(0))\n",
    "                classifier_label = Categorical(classifier_probs).sample().item()\n",
    "\n",
    "\n",
    "                labels_type_1[i].append((pred_label_pa, pred_label_pc, classifier_label))\n",
    "precs_t1 = []\n",
    "for i in range(len(labels_type_1)):\n",
    "    precs_t1.append(get_precisions(np.array(labels_type_1[i]), np.array(real_labels)))\n",
    "\n",
    "precs_t1 = np.array(precs_t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.20641682, 0.10461041, 0.04502561]),\n",
       " array([0.00287611, 0.00154725, 0.        ]))"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precs_t1.mean(axis=0), precs_t1.std(axis=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### type 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/11127 [00:00<?, ?it/s]/var/folders/ct/kvp_zk9j387g9f0jks9lbxvc0000gn/T/ipykernel_87929/485499444.py:9: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  p = F.softmax(idks[top100_inds])\n",
      "100%|██████████| 11127/11127 [04:42<00:00, 39.45it/s]\n"
     ]
    }
   ],
   "source": [
    "#need to get dot b\n",
    "sd = 1e-2\n",
    "\n",
    "cadot = deepcopy(ca)\n",
    "ccdot = deepcopy(cc)\n",
    "for param in cadot.parameters():\n",
    "    param.data.copy_(param.data + np.random.random()*sd)\n",
    "for param in ccdot.parameters():\n",
    "    param.data.copy_(param.data + np.random.random()*sd)\n",
    "\n",
    "\n",
    "pc = ccdot(torch.stack(obs_img))\n",
    "pa = cadot(torch.stack(obs_img))\n",
    "labels_type_2 = [[],[],[],[],[]]\n",
    "for img in tqdm(missing):\n",
    "\n",
    "        image, pred_label_pc = img[0], img[1]\n",
    "        \n",
    "        for i in range(5):\n",
    "                pred_label_pa = pmm(image, cadot, pa, obs_lbls)\n",
    "                pred_label_pc = pmm(image, ccdot, pc, obs_lbls)\n",
    "                classifier_probs = cc(image.unsqueeze(0))\n",
    "                classifier_label = Categorical(classifier_probs).sample().item()\n",
    "\n",
    "\n",
    "                labels_type_2[i].append((pred_label_pa, pred_label_pc, classifier_label))\n",
    "precs_t2 = []\n",
    "for i in range(len(labels_type_2)):\n",
    "    precs_t2.append(get_precisions(np.array(labels_type_2[i]), np.array(real_labels)))\n",
    "\n",
    "precs_t2 = np.array(precs_t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.24019053, 0.10484407, 0.04502561]),\n",
       " array([0.00300047, 0.00251743, 0.        ]))"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precs_t2.mean(axis=0), precs_t2.std(axis=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### type 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/11127 [00:00<?, ?it/s]/var/folders/ct/kvp_zk9j387g9f0jks9lbxvc0000gn/T/ipykernel_87929/485499444.py:9: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  p = F.softmax(idks[top100_inds])\n",
      "100%|██████████| 11127/11127 [04:34<00:00, 40.56it/s]\n"
     ]
    }
   ],
   "source": [
    "#need to get dot b\n",
    "sd = 1e-2\n",
    "\n",
    "cadot = deepcopy(ca)\n",
    "ccdot = deepcopy(cc)\n",
    "for param in cadot.parameters():\n",
    "    param.data.copy_(param.data + np.random.random()*sd)\n",
    "for param in ccdot.parameters():\n",
    "    param.data.copy_(param.data + np.random.random()*sd)\n",
    "\n",
    "caddot = deepcopy(cadot)\n",
    "ccddot = deepcopy(ccdot)\n",
    "for param in caddot.parameters():\n",
    "    param.data.copy_(param.data + np.random.random()*sd)\n",
    "for param in ccddot.parameters():\n",
    "    param.data.copy_(param.data + np.random.random()*sd)\n",
    "\n",
    "\n",
    "pc = ccdot(torch.stack(obs_img))\n",
    "pa = cadot(torch.stack(obs_img))\n",
    "labels_type_3 = [[],[],[],[],[]]\n",
    "for img in tqdm(missing):\n",
    "\n",
    "        image, pred_label_pc = img[0], img[1]\n",
    "        \n",
    "        for i in range(5):\n",
    "                pred_label_pa = pmm(image, caddot, pa, obs_lbls)\n",
    "                pred_label_pc = pmm(image, ccddot, pc, obs_lbls)\n",
    "                classifier_probs = cc(image.unsqueeze(0))\n",
    "                classifier_label = Categorical(classifier_probs).sample().item()\n",
    "\n",
    "\n",
    "                labels_type_3[i].append((pred_label_pa, pred_label_pc, classifier_label))\n",
    "precs_t3 = []\n",
    "for i in range(len(labels_type_3)):\n",
    "    precs_t3.append(get_precisions(np.array(labels_type_3[i]), np.array(real_labels)))\n",
    "\n",
    "precs_t3 = np.array(precs_t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.20898715, 0.10577874, 0.04502561]),\n",
       " array([0.00292799, 0.00228139, 0.        ]))"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precs_t3.mean(axis=0), precs_t3.std(axis=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating all three as missingness increases (MNAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_11 = pickle.load(open(\"pmm_data_betas_1_1.pkl\",'rb'))\n",
    "data_101 = pickle.load(open(\"pmm_data_betas_10_1.pkl\",'rb'))\n",
    "data_201 = pickle.load(open(\"pmm_data_betas_20_1.pkl\",'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_labels_11 = [i[1] for i in data_11['missing']]\n",
    "real_labels_101 = [i[1] for i in data_101['missing']]\n",
    "real_labels_201 = [i[1] for i in data_201['missing']]\n",
    "\n",
    "obs_img_11 = [i[0] for i in data_11['obs']]\n",
    "obs_img_101 = [i[0] for i in data_101['obs']]\n",
    "obs_img_201 = [i[0] for i in data_201['obs']]\n",
    "\n",
    "\n",
    "\n",
    "obs_lbls_11 = [i[1] for i in data_11['obs']]\n",
    "obs_lbls_101 = [i[1] for i in data_101['obs']]\n",
    "obs_lbls_201 = [i[1] for i in data_201['obs']]\n",
    "\n",
    "missing_11 = data_11['missing']\n",
    "missing_101 = data_101['missing']\n",
    "missing_201 = data_201['missing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_lbls_11 = np.array([i[1] for i in data_11['obs']])\n",
    "obs_lbls_101 = np.array([i[1] for i in data_101['obs']])\n",
    "obs_lbls_201 = np.array([i[1] for i in data_201['obs']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/29294 [00:00<?, ?it/s]/var/folders/ct/kvp_zk9j387g9f0jks9lbxvc0000gn/T/ipykernel_90727/485499444.py:9: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  p = F.softmax(idks[top100_inds])\n",
      "100%|██████████| 29294/29294 [07:23<00:00, 66.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46775/46775 [10:14<00:00, 76.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46976/46976 [09:54<00:00, 78.97it/s]\n"
     ]
    }
   ],
   "source": [
    "cc11 = torch.load(\"net_classifier_beta_1_1.pt\")\n",
    "cc51 = torch.load(\"net_classifier_beta_5_1.pt\")\n",
    "cc101 = torch.load(\"net_classifier_beta_10_1.pt\")\n",
    "cc201 = torch.load(\"net_classifier_beta_20_1.pt\")\n",
    "ca11 = torch.load(\"net_autoencoder_beta_1_1.pt\")\n",
    "ca51 = torch.load(\"net_autoencoder_beta_5_1.pt\")\n",
    "ca101 = torch.load(\"net_autoencoder_beta_10_1.pt\")\n",
    "ca201 = torch.load(\"net_autoencoder_beta_20_1.pt\")\n",
    "\n",
    "n_imputations = 5\n",
    "\n",
    "\n",
    "pc_11 = cc11(torch.stack(obs_img_11))\n",
    "pc_101 = cc11(torch.stack(obs_img_101))\n",
    "pc_201 = cc11(torch.stack(obs_img_201))\n",
    "pa_11 = ca11(torch.stack(obs_img_11))\n",
    "pa_101 = ca11(torch.stack(obs_img_101))\n",
    "pa_201 = ca11(torch.stack(obs_img_201))\n",
    "\n",
    "precs_11 = []\n",
    "precs_51 = []\n",
    "precs_101 = []\n",
    "precs_201 = []\n",
    "\n",
    "## classifier on all three\n",
    "labels_11 = [[],[],[], [],[]]\n",
    "print('11s')\n",
    "for img in tqdm(missing_11):\n",
    "\n",
    "        image, pred_label_pc = img[0], img[1]\n",
    "        \n",
    "        for i in range(5):\n",
    "                pred_label_pa = pmm(image, ca11 ,pa_11, obs_lbls_11)\n",
    "                pred_label_pc = pmm(image, cc11,pc_11, obs_lbls_11)\n",
    "                classifier_probs = cc11(image.unsqueeze(0))\n",
    "                classifier_label = Categorical(classifier_probs).sample().item()\n",
    "\n",
    "\n",
    "                labels_11[i].append((pred_label_pa, pred_label_pc, classifier_label))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "labels_101 = [[],[],[], [],[]]\n",
    "print('101s')\n",
    "for img in tqdm(missing_101):\n",
    "\n",
    "        image, pred_label_pc = img[0], img[1]\n",
    "        \n",
    "        for i in range(5):\n",
    "                pred_label_pa = pmm(image, ca101,pa_101, obs_lbls_101)\n",
    "                pred_label_pc = pmm(image, cc101,pc_101, obs_lbls_101)\n",
    "                classifier_probs = cc101(image.unsqueeze(0))\n",
    "                classifier_label = Categorical(classifier_probs).sample().item()\n",
    "\n",
    "\n",
    "                labels_101[i].append((pred_label_pa, pred_label_pc, classifier_label))\n",
    "\n",
    "\n",
    "labels_201 = [[],[],[], [],[]]\n",
    "print('201s')\n",
    "for img in tqdm(missing_201):\n",
    "\n",
    "        image, pred_label_pc = img[0], img[1]\n",
    "        \n",
    "        for i in range(5):\n",
    "                pred_label_pa = pmm(image, ca201, pa_201, obs_lbls_201)\n",
    "                pred_label_pc = pmm(image, cc201, pc_201, obs_lbls_201)\n",
    "                classifier_probs = cc201(image.unsqueeze(0))\n",
    "                classifier_label = Categorical(classifier_probs).sample().item()\n",
    "\n",
    "\n",
    "                labels_201[i].append((pred_label_pa, pred_label_pc, classifier_label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#precision for 11\n",
    "precs_11 = []\n",
    "for i in range(len(labels_11)):\n",
    "    precs_11.append(get_precisions(np.array(labels_11[i]), np.array(real_labels_11)))\n",
    "\n",
    "precs_11 = np.array(precs_11)\n",
    "\n",
    "#precisions for 101\n",
    "precs_101 = []\n",
    "for i in range(len(labels_11)):\n",
    "    precs_101.append(get_precisions(np.array(labels_101[i]), np.array(real_labels_101)))\n",
    "\n",
    "precs_101 = np.array(precs_101)\n",
    "\n",
    "#precisions for 201\n",
    "precs_201 = []\n",
    "for i in range(len(labels_11)):\n",
    "    precs_201.append(get_precisions(np.array(labels_201[i]), np.array(real_labels_201)))\n",
    "\n",
    "precs_201 = np.array(precs_201)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.1725268 , 0.05391548, 0.00604219]),\n",
       " array([0.00161391, 0.00143773, 0.        ]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precs_11.mean(axis=0), precs_11.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.12253127, 0.09505505, 0.08722608]),\n",
       " array([0.00132201, 0.00108351, 0.        ]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precs_101.mean(axis=0), precs_101.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.12064033, 0.0948314 , 0.10060456]),\n",
       " array([1.19326833e-03, 6.92206072e-04, 1.38777878e-17]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precs_201.mean(axis=0), precs_201.std(axis=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the different types of PMM (MNAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = torch.load(\"net_classifier_mnar.pt\")\n",
    "ca = torch.load(\"net_autoencoder_mnar.pt\")\n",
    "\n",
    "\n",
    "data = pickle.load(open('pmm_data_mnar.pkl','rb'))\n",
    "real_labels = [i[1] for i in data['missing']]\n",
    "obs_img = [i[0] for i in data['obs']]\n",
    "obs_lbls = np.array([i[1] for i in data['obs']])\n",
    "missing = data['missing']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### type 0\n",
    "straight up pmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/28423 [00:00<?, ?it/s]/var/folders/ct/kvp_zk9j387g9f0jks9lbxvc0000gn/T/ipykernel_90727/485499444.py:9: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  p = F.softmax(idks[top100_inds])\n",
      "100%|██████████| 28423/28423 [09:15<00:00, 51.17it/s]\n"
     ]
    }
   ],
   "source": [
    "pc = cc(torch.stack(obs_img))\n",
    "pa = ca(torch.stack(obs_img))\n",
    "labels_type_0 = [[],[],[],[],[]]\n",
    "for img in tqdm(missing):\n",
    "\n",
    "        image, pred_label_pc = img[0], img[1]\n",
    "        \n",
    "        for i in range(5):\n",
    "                pred_label_pa = pmm(image, ca, pa, obs_lbls)\n",
    "                pred_label_pc = pmm(image, cc, pc, obs_lbls)\n",
    "                classifier_probs = cc(image.unsqueeze(0))\n",
    "                classifier_label = Categorical(classifier_probs).sample().item()\n",
    "\n",
    "\n",
    "                labels_type_0[i].append((pred_label_pa, pred_label_pc, classifier_label))\n",
    "precs_t0 = []\n",
    "for i in range(len(labels_type_0)):\n",
    "    precs_t0.append(get_precisions(np.array(labels_type_0[i]), np.array(real_labels)))\n",
    "\n",
    "precs_t0 = np.array(precs_t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.19810013, 0.19164761, 0.23042606]),\n",
       " array([0.00192737, 0.0011397 , 0.00096547]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precs_t0.mean(axis=0), precs_t0.std(axis=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### type 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/28423 [00:00<?, ?it/s]/var/folders/ct/kvp_zk9j387g9f0jks9lbxvc0000gn/T/ipykernel_90727/485499444.py:9: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  p = F.softmax(idks[top100_inds])\n",
      "100%|██████████| 28423/28423 [08:47<00:00, 53.86it/s]\n"
     ]
    }
   ],
   "source": [
    "#need to get dot b\n",
    "sd = 1e-2\n",
    "\n",
    "cadot = deepcopy(ca)\n",
    "ccdot = deepcopy(cc)\n",
    "for param in cadot.parameters():\n",
    "    param.data.copy_(param.data + np.random.random()*sd)\n",
    "for param in ccdot.parameters():\n",
    "    param.data.copy_(param.data + np.random.random()*sd)\n",
    "\n",
    "\n",
    "pc = cc(torch.stack(obs_img))\n",
    "pa = ca(torch.stack(obs_img))\n",
    "labels_type_1 = [[],[],[],[],[]]\n",
    "for img in tqdm(missing):\n",
    "\n",
    "        image, pred_label_pc = img[0], img[1]\n",
    "        \n",
    "        for i in range(5):\n",
    "                pred_label_pa = pmm(image, cadot, pa, obs_lbls)\n",
    "                pred_label_pc = pmm(image, ccdot, pc, obs_lbls)\n",
    "                classifier_probs = cc(image.unsqueeze(0))\n",
    "                classifier_label = Categorical(classifier_probs).sample().item()\n",
    "\n",
    "\n",
    "                labels_type_1[i].append((pred_label_pa, pred_label_pc, classifier_label))\n",
    "precs_t1 = []\n",
    "for i in range(len(labels_type_1)):\n",
    "    precs_t1.append(get_precisions(np.array(labels_type_1[i]), np.array(real_labels)))\n",
    "\n",
    "precs_t1 = np.array(precs_t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.14601555, 0.18786194, 0.23078493]),\n",
       " array([0.00184707, 0.00023295, 0.00082918]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precs_t1.mean(axis=0), precs_t1.std(axis=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### type 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/28423 [00:00<?, ?it/s]/var/folders/ct/kvp_zk9j387g9f0jks9lbxvc0000gn/T/ipykernel_90727/485499444.py:9: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  p = F.softmax(idks[top100_inds])\n",
      "100%|██████████| 28423/28423 [08:17<00:00, 57.15it/s]\n"
     ]
    }
   ],
   "source": [
    "#need to get dot b\n",
    "sd = 1e-2\n",
    "\n",
    "cadot = deepcopy(ca)\n",
    "ccdot = deepcopy(cc)\n",
    "for param in cadot.parameters():\n",
    "    param.data.copy_(param.data + np.random.random()*sd)\n",
    "for param in ccdot.parameters():\n",
    "    param.data.copy_(param.data + np.random.random()*sd)\n",
    "\n",
    "\n",
    "pc = ccdot(torch.stack(obs_img))\n",
    "pa = cadot(torch.stack(obs_img))\n",
    "labels_type_2 = [[],[],[],[],[]]\n",
    "for img in tqdm(missing):\n",
    "\n",
    "        image, pred_label_pc = img[0], img[1]\n",
    "        \n",
    "        for i in range(5):\n",
    "                pred_label_pa = pmm(image, cadot, pa, obs_lbls)\n",
    "                pred_label_pc = pmm(image, ccdot, pc, obs_lbls)\n",
    "                classifier_probs = cc(image.unsqueeze(0))\n",
    "                classifier_label = Categorical(classifier_probs).sample().item()\n",
    "\n",
    "\n",
    "                labels_type_2[i].append((pred_label_pa, pred_label_pc, classifier_label))\n",
    "precs_t2 = []\n",
    "for i in range(len(labels_type_2)):\n",
    "    precs_t2.append(get_precisions(np.array(labels_type_2[i]), np.array(real_labels)))\n",
    "\n",
    "precs_t2 = np.array(precs_t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.18826303, 0.18624354, 0.23047532]),\n",
       " array([0.0016804 , 0.00206312, 0.0010407 ]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precs_t2.mean(axis=0), precs_t2.std(axis=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### type 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/28423 [00:00<?, ?it/s]/var/folders/ct/kvp_zk9j387g9f0jks9lbxvc0000gn/T/ipykernel_90727/485499444.py:9: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  p = F.softmax(idks[top100_inds])\n",
      "100%|██████████| 28423/28423 [08:37<00:00, 54.93it/s]\n"
     ]
    }
   ],
   "source": [
    "#need to get dot b\n",
    "sd = 1e-2\n",
    "\n",
    "cadot = deepcopy(ca)\n",
    "ccdot = deepcopy(cc)\n",
    "for param in cadot.parameters():\n",
    "    param.data.copy_(param.data + np.random.random()*sd)\n",
    "for param in ccdot.parameters():\n",
    "    param.data.copy_(param.data + np.random.random()*sd)\n",
    "\n",
    "caddot = deepcopy(cadot)\n",
    "ccddot = deepcopy(ccdot)\n",
    "for param in caddot.parameters():\n",
    "    param.data.copy_(param.data + np.random.random()*sd)\n",
    "for param in ccddot.parameters():\n",
    "    param.data.copy_(param.data + np.random.random()*sd)\n",
    "\n",
    "\n",
    "pc = ccdot(torch.stack(obs_img))\n",
    "pa = cadot(torch.stack(obs_img))\n",
    "labels_type_3 = [[],[],[],[],[]]\n",
    "for img in tqdm(missing):\n",
    "\n",
    "        image, pred_label_pc = img[0], img[1]\n",
    "        \n",
    "        for i in range(5):\n",
    "                pred_label_pa = pmm(image, caddot, pa, obs_lbls)\n",
    "                pred_label_pc = pmm(image, ccddot, pc, obs_lbls)\n",
    "                classifier_probs = cc(image.unsqueeze(0))\n",
    "                classifier_label = Categorical(classifier_probs).sample().item()\n",
    "\n",
    "\n",
    "                labels_type_3[i].append((pred_label_pa, pred_label_pc, classifier_label))\n",
    "precs_t3 = []\n",
    "for i in range(len(labels_type_3)):\n",
    "    precs_t3.append(get_precisions(np.array(labels_type_3[i]), np.array(real_labels)))\n",
    "\n",
    "precs_t3 = np.array(precs_t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.12198572, 0.19461   , 0.23036977]),\n",
       " array([0.0006725 , 0.0006436 , 0.00065723]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precs_t3.mean(axis=0), precs_t3.std(axis=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More MNAR lookins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_11 = pickle.load(open(\"pmm_data_betas_1_1.pkl\",'rb'))\n",
    "data_1010 = pickle.load(open(\"pmm_data_betas_10_10.pkl\",'rb'))\n",
    "data_5050 = pickle.load(open(\"pmm_data_betas_50_50.pkl\",'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_labels_11 = [i[1] for i in data_11['missing']]\n",
    "real_labels_1010 = [i[1] for i in data_1010['missing']]\n",
    "real_labels_5050 = [i[1] for i in data_5050['missing']]\n",
    "\n",
    "obs_img_11 = [i[0] for i in data_11['obs']]\n",
    "obs_img_1010 = [i[0] for i in data_1010['obs']]\n",
    "obs_img_5050 = [i[0] for i in data_5050['obs']]\n",
    "\n",
    "\n",
    "\n",
    "obs_lbls_11 = [i[1] for i in data_11['obs']]\n",
    "obs_lbls_1010 = [i[1] for i in data_1010['obs']]\n",
    "obs_lbls_5050 = [i[1] for i in data_5050['obs']]\n",
    "\n",
    "missing_11 = data_11['missing']\n",
    "missing_1010 = data_1010['missing']\n",
    "missing_5050 = data_5050['missing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_lbls_11 = np.array([i[1] for i in data_11['obs']])\n",
    "obs_lbls_1010 = np.array([i[1] for i in data_1010['obs']])\n",
    "obs_lbls_5050 = np.array([i[1] for i in data_5050['obs']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nathandelara/mcgill/u2/math782/fin_proj3/PMM_for_images.py:86: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = F.softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/26573 [00:00<?, ?it/s]/var/folders/ct/kvp_zk9j387g9f0jks9lbxvc0000gn/T/ipykernel_90727/485499444.py:9: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  p = F.softmax(idks[top100_inds])\n",
      "100%|██████████| 26573/26573 [06:52<00:00, 64.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1010s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46775/46775 [13:00<00:00, 59.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5050s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46976/46976 [14:40<00:00, 53.36it/s]\n"
     ]
    }
   ],
   "source": [
    "cc11 = torch.load(\"net_classifier_beta_1_1.pt\")\n",
    "cc1010 = torch.load(\"net_classifier_beta_10_10.pt\")\n",
    "cc5050 = torch.load(\"net_classifier_beta_50_50.pt\")\n",
    "ca11 = torch.load(\"net_autoencoder_beta_1_1.pt\")\n",
    "ca1010 = torch.load(\"net_autoencoder_beta_10_10.pt\")\n",
    "ca5050 = torch.load(\"net_autoencoder_beta_50_50.pt\")\n",
    "\n",
    "n_imputations = 5\n",
    "\n",
    "\n",
    "pc_11 = cc11(torch.stack(obs_img_11))\n",
    "pc_1010 = cc1010(torch.stack(obs_img_1010))\n",
    "pc_5050 = cc5050(torch.stack(obs_img_5050))\n",
    "pa_11 = ca11(torch.stack(obs_img_11))\n",
    "pa_1010 = ca1010(torch.stack(obs_img_1010))\n",
    "pa_5050 = ca5050(torch.stack(obs_img_5050))\n",
    "\n",
    "precs_11 = []\n",
    "\n",
    "precs_1010 = []\n",
    "precs_5050 = []\n",
    "\n",
    "## classifier on all three\n",
    "labels_11 = [[],[],[], [],[]]\n",
    "print('11s')\n",
    "for img in tqdm(missing_11):\n",
    "\n",
    "        image, pred_label_pc = img[0], img[1]\n",
    "        \n",
    "        for i in range(5):\n",
    "                pred_label_pa = pmm(image, ca11 ,pa_11, obs_lbls_11)\n",
    "                pred_label_pc = pmm(image, cc11,pc_11, obs_lbls_11)\n",
    "                classifier_probs = cc11(image.unsqueeze(0))\n",
    "                classifier_label = Categorical(classifier_probs).sample().item()\n",
    "\n",
    "\n",
    "                labels_11[i].append((pred_label_pa, pred_label_pc, classifier_label))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "labels_1010 = [[],[],[], [],[]]\n",
    "print('1010s')\n",
    "for img in tqdm(missing_101):\n",
    "\n",
    "        image, pred_label_pc = img[0], img[1]\n",
    "        \n",
    "        for i in range(5):\n",
    "                pred_label_pa = pmm(image, ca1010,pa_1010, obs_lbls_1010)\n",
    "                pred_label_pc = pmm(image, cc1010,pc_1010, obs_lbls_1010)\n",
    "                classifier_probs = cc101(image.unsqueeze(0))\n",
    "                classifier_label = Categorical(classifier_probs).sample().item()\n",
    "\n",
    "\n",
    "                labels_1010[i].append((pred_label_pa, pred_label_pc, classifier_label))\n",
    "\n",
    "\n",
    "labels_5050 = [[],[],[], [],[]]\n",
    "print('5050s')\n",
    "for img in tqdm(missing_201):\n",
    "\n",
    "        image, pred_label_pc = img[0], img[1]\n",
    "        \n",
    "        for i in range(5):\n",
    "                pred_label_pa = pmm(image, ca5050, pa_5050, obs_lbls_5050)\n",
    "                pred_label_pc = pmm(image, cc5050, pc_5050, obs_lbls_5050)\n",
    "                classifier_probs = cc201(image.unsqueeze(0))\n",
    "                classifier_label = Categorical(classifier_probs).sample().item()\n",
    "\n",
    "\n",
    "                labels_5050[i].append((pred_label_pa, pred_label_pc, classifier_label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "precs_11 = []\n",
    "for i in range(len(labels_11)):\n",
    "    precs_11.append(get_precisions(np.array(labels_11[i]), np.array(real_labels_11)))\n",
    "\n",
    "precs_11 = np.array(precs_11)\n",
    "\n",
    "#precisions for 101\n",
    "precs_1010 = []\n",
    "for i in range(len(labels_11)):\n",
    "    precs_1010.append(get_precisions(np.array(labels_1010[i]), np.array(real_labels_1010)))\n",
    "\n",
    "precs_1010 = np.array(precs_1010)\n",
    "\n",
    "#precisions for 201\n",
    "precs_5050 = []\n",
    "for i in range(len(labels_11)):\n",
    "    precs_5050.append(get_precisions(np.array(labels_5050[i]), np.array(real_labels_5050)))\n",
    "\n",
    "precs_5050 = np.array(precs_5050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.21251646, 0.08390472, 0.01053701]),\n",
       " array([0.00119132, 0.00080452, 0.        ]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precs_11.mean(axis=0), precs_11.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.09663756, 0.06559436, 0.04553462]),\n",
       " array([0.00082265, 0.00143485, 0.        ]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precs_1010.mean(axis=0), precs_1010.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.09983087, 0.10144796, 0.09224042]),\n",
       " array([0.00161001, 0.00112986, 0.        ]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precs_5050.mean(axis=0), precs_5050.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
